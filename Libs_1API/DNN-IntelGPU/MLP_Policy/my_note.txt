Mar 19, 2023

Test with XPU on DevCloud:

===============================================
For CPU - Steps to run and view correct output:
===============================================
1. Navigate to 
$ cd /home/u186670/oneAPI-samples/AI-and-Analytics/Getting-Started-Samples/Intel_Extension_For_PyTorch_GettingStarted
2. $ vim hello.py
3. copy the content of mlp.py into hello.py
4. replace the last line of run.sh with [python hello.py]
5. $ ./q ./run.sh
6. output in screenshots/cpu_out0&1

=======================================
For GPU - Steps to run and view output:
=======================================
### for hello.py in run.sh:
1. uncomment the liness with "xpu"
2. $ ./q ./run.sh
########################################################################
# End of output for job 2257546.v-qsvr-1.aidevcloud
# Date: Sun 19 Mar 2023 03:04:08 PM PDT
########################################################################

Traceback (most recent call last):
  File "/home/u186670/oneAPI-samples/AI-and-Analytics/Getting-Started-Samples/Intel_Extension_For_PyTorch_GettingStarted/hello.py", line 272, in <module>
    simple_dqn = simple_dqn.to("xpu")
  File "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 987, in to
    return self._apply(convert)
  File "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 639, in _apply
    module._apply(fn)
  File "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 662, in _apply
    param_applied = fn(param)
  File "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 985, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: PyTorch is not linked with support for xpu devices


### for Intel_Extension_For_PyTorch_Hello_World.py (original example provided in oneAPI-samples github) in run.sh:
1. $ patch < ./codes_for_py/gpu.patch
2. $ ./q ./run.sh
########################################################################
# End of output for job 2257550.v-qsvr-1.aidevcloud
# Date: Sun 19 Mar 2023 03:16:03 PM PDT
########################################################################

[W OperatorEntry.cpp:150] Warning: Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: torchvision::nms
    no debug info
  dispatch key: CPU
  previous kernel: registered at /build/intel-pytorch-extension/csrc/cpu/aten/TorchVisionNms.cpp:47
       new kernel: registered at /opt/workspace/vision/torchvision/csrc/ops/cpu/nms_kernel.cpp:112 (function registerKernel)
/glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/intel_extension_for_pytorch/xpu/lazy_init.py:73: UserWarning: DPCPP Device count is zero! (Triggered internally at /build/intel-pytorch-extension/csrc/gpu/runtime/Device.cpp:120.)
  _C._initExtension()
/glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:983: UserWarning: dpcppSetDevice: device_id is out of range (Triggered internally at /build/intel-pytorch-extension/csrc/gpu/runtime/Device.cpp:159.)
  return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,
Traceback (most recent call last):
  File "/home/u186670/oneAPI-samples/AI-and-Analytics/Getting-Started-Samples/Intel_Extension_For_PyTorch_GettingStarted/Intel_Extension_For_PyTorch_Hello_World.py", line 123, in <module>
    main()
  File "/home/u186670/oneAPI-samples/AI-and-Analytics/Getting-Started-Samples/Intel_Extension_For_PyTorch_GettingStarted/Intel_Extension_For_PyTorch_Hello_World.py", line 77, in main
    model = model.to("xpu", memory_format=torch.channels_last)
  File "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 987, in to
    return self._apply(convert)
  File "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 639, in _apply
    module._apply(fn)
  File "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 662, in _apply
    param_applied = fn(param)
  File "/glob/development-tools/versions/oneapi/2023.0.1/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 983, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,
RuntimeError: Number of dpcpp devices should be greater than zero!